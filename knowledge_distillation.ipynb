{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "thCwtDPECgxi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vitfDBXPCgxk",
        "outputId": "206206f8-269c-4e50-dc7c-65724f30cc34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QQ8uDWdXCgxl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "50000\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.CIFAR10(\"dataset\", train=True, download=True, transform=train_transforms)\n",
        "print(len(train_data))\n",
        "\n",
        "test_data = datasets.CIFAR10(\"dataset\", train=False, transform=test_transforms)\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-44avHWWCgxm",
        "outputId": "6cc152c3-6134-4cc6-e0c6-c3f1b3f693bf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yI90v34dCgxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "outputs": [],
      "source": [
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TeacherModel, self).__init__()\n",
        "\n",
        "        self.convolutional_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.fully_connected_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convolutional_layer(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fully_connected_layer(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xb6vCKhoCgxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "outputs": [],
      "source": [
        "class StudentModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StudentModel, self).__init__()\n",
        "\n",
        "        self.convolutional_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(negative_slope=0.02, inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=3),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.fully_connected_layer = nn.Sequential(\n",
        "            nn.Linear(2048, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convolutional_layer(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fully_connected_layer(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UAL9c37cCgxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "outputs": [],
      "source": [
        "initial_student_model = StudentModel()\n",
        "distilled_student_model = StudentModel()\n",
        "teacher_model = TeacherModel()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Dnd_626kCgxo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "outputs": [],
      "source": [
        "temperature = 20.0\n",
        "distillation_weight = 0.5\n",
        "\n",
        "optimizer_teacher = optim.SGD(teacher_model.parameters(), 0.01)\n",
        "optimizer_student = optim.SGD(initial_student_model.parameters(), 0.01)\n",
        "optimizer_distilled_student = optim.SGD(distilled_student_model.parameters(), 0.05)\n",
        "\n",
        "loss_func = nn.KLDivLoss(reduction='batchmean').to(device)\n",
        "cross_entropy_loss = nn.CrossEntropyLoss(reduction='mean').to(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NlwIy1FgCgxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "outputs": [],
      "source": [
        "def train_teacher(epochs, teacher_model):\n",
        "    teacher_model = teacher_model.to(device)\n",
        "    teacher_model.train()\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    best_val_acc = 0.0\n",
        "    best_teacher_model_weights = deepcopy(teacher_model.state_dict())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_epoch_loss = 0.0\n",
        "        val_epoch_loss = 0.0\n",
        "        train_correct = 0.0\n",
        "        val_correct = 0.0\n",
        "\n",
        "        teacher_model.train()\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        for (data, label) in train_loader:\n",
        "            if i % 200 == 0:\n",
        "                print(f'epoch {epoch}/{epochs} batch {i}/{len(train_loader)}')\n",
        "\n",
        "            i += 1\n",
        "\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            out = teacher_model(data)\n",
        "            predicted = out.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            train_correct += predicted.eq(label.view_as(predicted)).sum().item()\n",
        "            loss = cross_entropy_loss(out, label)\n",
        "\n",
        "            optimizer_teacher.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_teacher.step()\n",
        "\n",
        "            train_epoch_loss += loss.item()\n",
        "\n",
        "        train_epoch_loss /= len(train_loader.dataset)\n",
        "        train_epoch_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            teacher_model.eval()\n",
        "\n",
        "            for (data, label) in test_loader:\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "                out = teacher_model(data)\n",
        "                predicted = out.argmax(dim=1, keepdim=True)\n",
        "                val_correct += predicted.eq(label.view_as(predicted)).sum().item()\n",
        "                loss = cross_entropy_loss(out, label)\n",
        "                val_epoch_loss += loss.item()\n",
        "\n",
        "        val_epoch_acc = val_correct / len(test_loader.dataset)\n",
        "        val_epoch_loss /= len(test_loader.dataset)\n",
        "\n",
        "        if val_epoch_acc > best_val_acc:\n",
        "            best_val_acc = val_epoch_acc\n",
        "            best_teacher_model_weights = deepcopy(teacher_model.state_dict())\n",
        "\n",
        "        train_loss_list.append(train_epoch_loss)\n",
        "        val_loss_list.append(val_epoch_loss)\n",
        "\n",
        "        print(\n",
        "            f\"epoch: {epoch + 1} \\n train loss: {train_epoch_loss:4.4f}, train accuracy: {train_epoch_acc} \\n val loss: {val_epoch_loss} val accuracy: {val_epoch_acc}\\n\\n\")\n",
        "\n",
        "    teacher_model.load_state_dict(best_teacher_model_weights)\n",
        "\n",
        "    plt.plot(train_loss_list)\n",
        "    plt.plot(val_loss_list)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "T_y29lqiCgxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "outputs": [],
      "source": [
        "def train_student(epochs, initial_student_model):\n",
        "    initial_student_model = initial_student_model.to(device)\n",
        "    initial_student_model.train()\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    best_val_acc = 0.0\n",
        "    best_student_model_weights = deepcopy(initial_student_model.state_dict())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_epoch_loss = 0.0\n",
        "        val_epoch_loss = 0.0\n",
        "        train_correct = 0.0\n",
        "        val_correct = 0.0\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        initial_student_model.train()\n",
        "\n",
        "        for (data, label) in train_loader:\n",
        "            if i % 200 == 0:\n",
        "                print(f'epoch {epoch}/{epochs} batch {i}/{len(train_loader)}')\n",
        "\n",
        "            i += 1\n",
        "\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            out = initial_student_model(data)\n",
        "            pred = out.argmax(dim=1, keepdim=True)\n",
        "            train_correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "            loss = cross_entropy_loss(out, label)\n",
        "\n",
        "            optimizer_student.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_student.step()\n",
        "\n",
        "            train_epoch_loss += loss\n",
        "\n",
        "        train_epoch_loss /= len(train_loader.dataset)\n",
        "        train_epoch_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            initial_student_model.eval()\n",
        "\n",
        "            for (data, label) in test_loader:\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "                out = initial_student_model(data)\n",
        "                pred = out.argmax(dim=1, keepdim=True)\n",
        "\n",
        "                val_correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "                loss = cross_entropy_loss(out, label)\n",
        "\n",
        "                val_epoch_loss += loss\n",
        "\n",
        "        val_epoch_acc = val_correct / len(test_loader.dataset)\n",
        "        val_epoch_loss /= len(test_loader.dataset)\n",
        "\n",
        "        if val_epoch_acc > best_val_acc:\n",
        "            best_val_acc = val_epoch_acc\n",
        "            best_student_model_weights = deepcopy(initial_student_model.state_dict())\n",
        "\n",
        "        train_loss_list.append(train_epoch_loss.item())\n",
        "        val_loss_list.append(val_epoch_loss.item())\n",
        "\n",
        "        print(\n",
        "            f\"epoch: {epoch + 1} \\n train loss: {train_epoch_loss}, train accuracy: {train_epoch_acc} \\n val loss: {val_epoch_loss} val accuracy: {val_epoch_acc}\\n\\n\")\n",
        "\n",
        "    initial_student_model.load_state_dict(best_student_model_weights)\n",
        "    \n",
        "    plt.plot(train_loss_list)\n",
        "    plt.plot(val_loss_list)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xoY48whnCgxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "outputs": [],
      "source": [
        "def get_knowledge_distillation_loss(student_predicted, teacher_predicted, expected):\n",
        "    soft_teacher_out = F.softmax(teacher_predicted / temperature, dim=1)\n",
        "    soft_student_out = F.softmax(student_predicted / temperature, dim=1)\n",
        "\n",
        "    loss = (1 - distillation_weight) * F.cross_entropy(student_predicted, expected)\n",
        "    loss += (distillation_weight * temperature * temperature) * loss_func(soft_teacher_out, soft_student_out)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MC4ml8knCgxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "outputs": [],
      "source": [
        "def knowledge_distillation(epochs, distilled_student_model, teacher_model):\n",
        "    distilled_student_model = distilled_student_model.to(device)\n",
        "    teacher_model = teacher_model.to(device).eval()\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    best_val_acc = 0.0\n",
        "    best_distilled_student_model_weights = deepcopy(distilled_student_model.state_dict())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_epoch_loss = 0.0\n",
        "        val_epoch_loss = 0.0\n",
        "        train_correct = 0.0\n",
        "        val_correct = 0.0\n",
        "\n",
        "        distilled_student_model.train()\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        for (data, label) in train_loader:\n",
        "            if i % 200 == 0:\n",
        "                print(f'epoch {epoch}/{epochs} batch {i}/{len(train_loader)}')\n",
        "\n",
        "            i += 1\n",
        "\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            student_out = distilled_student_model(data)\n",
        "            teacher_out = teacher_model(data)\n",
        "            pred = student_out.argmax(dim=1, keepdim=True)\n",
        "            train_correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "            loss = get_knowledge_distillation_loss(student_out, teacher_out, label)\n",
        "\n",
        "            optimizer_distilled_student.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_distilled_student.step()\n",
        "\n",
        "            train_epoch_loss += loss\n",
        "\n",
        "        train_epoch_loss /= len(train_loader.dataset)\n",
        "        train_epoch_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            distilled_student_model.eval()\n",
        "\n",
        "            for (data, label) in test_loader:\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "                student_out = distilled_student_model(data)\n",
        "                teacher_out = teacher_model(data)\n",
        "                pred = student_out.argmax(dim=1, keepdim=True)\n",
        "                val_correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "                loss = get_knowledge_distillation_loss(student_out, teacher_out, label)\n",
        "                val_epoch_loss += loss\n",
        "\n",
        "        val_epoch_acc = val_correct / len(test_loader.dataset)\n",
        "        val_epoch_loss /= len(test_loader.dataset)\n",
        "\n",
        "        if val_epoch_acc > best_val_acc:\n",
        "            best_val_acc = val_epoch_acc\n",
        "            best_distilled_student_model_weights = deepcopy(distilled_student_model.state_dict())\n",
        "\n",
        "        train_loss_list.append(train_epoch_loss.item())\n",
        "        val_loss_list.append(val_epoch_loss.item())\n",
        "\n",
        "        print(\n",
        "            f\"epoch: {epoch + 1} \\n train loss: {train_epoch_loss}, train accuracy: {train_epoch_acc} \\n val loss: {val_epoch_loss} val accuracy: {val_epoch_acc}\\n\\n\")\n",
        "\n",
        "    distilled_student_model.load_state_dict(best_distilled_student_model_weights)\n",
        "\n",
        "    plt.plot(train_loss_list)\n",
        "    plt.plot(val_loss_list)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xEjNzVmwCgxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "outputs": [],
      "source": [
        "def get_model_accuracy(model):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    correct = 0\n",
        "    outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            outputs.append(output)\n",
        "\n",
        "            predicted = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            correct += predicted.eq(target.view_as(predicted)).sum().item()\n",
        "\n",
        "    return correct / len(test_loader.dataset)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2w546ZayCgxr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "outputs": [],
      "source": [
        "def print_models_evaluation_accuracy(initial_student_model, teacher_model, distilled_student_model):\n",
        "    initial_student_model_copied = deepcopy(initial_student_model).to(device)\n",
        "    teacher_model_copied = deepcopy(teacher_model).to(device)\n",
        "    distilled_student_model_copied = deepcopy(distilled_student_model).to(device)\n",
        "\n",
        "    teacher_acc = get_model_accuracy(teacher_model_copied)\n",
        "    initial_student_acc = get_model_accuracy(initial_student_model_copied)\n",
        "    distilled_student_acc = get_model_accuracy(distilled_student_model_copied)\n",
        "\n",
        "    print(\n",
        "        f\" teacher accuracy: {teacher_acc:0.4} \\n student accuracy: {initial_student_acc:0.4} \\n distilled student accuracy: {distilled_student_acc:0.4}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BvH7W2cvCgxr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/25 batch 0/1563\n",
            "epoch 0/25 batch 200/1563\n",
            "epoch 0/25 batch 400/1563\n",
            "epoch 0/25 batch 600/1563\n",
            "epoch 0/25 batch 800/1563\n",
            "epoch 0/25 batch 1000/1563\n",
            "epoch 0/25 batch 1200/1563\n",
            "epoch 0/25 batch 1400/1563\n",
            "epoch: 1 \n",
            " train loss: 0.0471, train accuracy: 0.44478 \n",
            " val loss: 0.036151153814792635 val accuracy: 0.5752\n",
            "\n",
            "\n",
            "epoch 1/25 batch 0/1563\n",
            "epoch 1/25 batch 200/1563\n",
            "epoch 1/25 batch 400/1563\n",
            "epoch 1/25 batch 600/1563\n",
            "epoch 1/25 batch 800/1563\n",
            "epoch 1/25 batch 1000/1563\n",
            "epoch 1/25 batch 1200/1563\n",
            "epoch 1/25 batch 1400/1563\n",
            "epoch: 2 \n",
            " train loss: 0.0314, train accuracy: 0.63806 \n",
            " val loss: 0.02786839281618595 val accuracy: 0.6838\n",
            "\n",
            "\n",
            "epoch 2/25 batch 0/1563\n",
            "epoch 2/25 batch 200/1563\n",
            "epoch 2/25 batch 400/1563\n",
            "epoch 2/25 batch 600/1563\n",
            "epoch 2/25 batch 800/1563\n",
            "epoch 2/25 batch 1000/1563\n",
            "epoch 2/25 batch 1200/1563\n",
            "epoch 2/25 batch 1400/1563\n",
            "epoch: 3 \n",
            " train loss: 0.0248, train accuracy: 0.7191 \n",
            " val loss: 0.02247040946483612 val accuracy: 0.7539\n",
            "\n",
            "\n",
            "epoch 3/25 batch 0/1563\n",
            "epoch 3/25 batch 200/1563\n",
            "epoch 3/25 batch 400/1563\n",
            "epoch 3/25 batch 600/1563\n",
            "epoch 3/25 batch 800/1563\n",
            "epoch 3/25 batch 1000/1563\n",
            "epoch 3/25 batch 1200/1563\n",
            "epoch 3/25 batch 1400/1563\n",
            "epoch: 4 \n",
            " train loss: 0.0213, train accuracy: 0.764 \n",
            " val loss: 0.020937975534796715 val accuracy: 0.769\n",
            "\n",
            "\n",
            "epoch 4/25 batch 0/1563\n",
            "epoch 4/25 batch 200/1563\n",
            "epoch 4/25 batch 400/1563\n",
            "epoch 4/25 batch 600/1563\n",
            "epoch 4/25 batch 800/1563\n",
            "epoch 4/25 batch 1000/1563\n",
            "epoch 4/25 batch 1200/1563\n",
            "epoch 4/25 batch 1400/1563\n",
            "epoch: 5 \n",
            " train loss: 0.0189, train accuracy: 0.79116 \n",
            " val loss: 0.025419598887860776 val accuracy: 0.7412\n",
            "\n",
            "\n",
            "epoch 5/25 batch 0/1563\n",
            "epoch 5/25 batch 200/1563\n",
            "epoch 5/25 batch 400/1563\n",
            "epoch 5/25 batch 600/1563\n",
            "epoch 5/25 batch 800/1563\n",
            "epoch 5/25 batch 1000/1563\n",
            "epoch 5/25 batch 1200/1563\n",
            "epoch 5/25 batch 1400/1563\n",
            "epoch: 6 \n",
            " train loss: 0.0170, train accuracy: 0.81376 \n",
            " val loss: 0.01729561708420515 val accuracy: 0.8102\n",
            "\n",
            "\n",
            "epoch 6/25 batch 0/1563\n",
            "epoch 6/25 batch 200/1563\n",
            "epoch 6/25 batch 400/1563\n",
            "epoch 6/25 batch 600/1563\n",
            "epoch 6/25 batch 800/1563\n",
            "epoch 6/25 batch 1000/1563\n",
            "epoch 6/25 batch 1200/1563\n",
            "epoch 6/25 batch 1400/1563\n",
            "epoch: 7 \n",
            " train loss: 0.0156, train accuracy: 0.82902 \n",
            " val loss: 0.01536841431260109 val accuracy: 0.8332\n",
            "\n",
            "\n",
            "epoch 7/25 batch 0/1563\n",
            "epoch 7/25 batch 200/1563\n",
            "epoch 7/25 batch 400/1563\n",
            "epoch 7/25 batch 600/1563\n",
            "epoch 7/25 batch 800/1563\n",
            "epoch 7/25 batch 1000/1563\n",
            "epoch 7/25 batch 1200/1563\n",
            "epoch 7/25 batch 1400/1563\n",
            "epoch: 8 \n",
            " train loss: 0.0144, train accuracy: 0.84062 \n",
            " val loss: 0.017984239145368338 val accuracy: 0.8111\n",
            "\n",
            "\n",
            "epoch 8/25 batch 0/1563\n",
            "epoch 8/25 batch 200/1563\n",
            "epoch 8/25 batch 400/1563\n",
            "epoch 8/25 batch 600/1563\n",
            "epoch 8/25 batch 800/1563\n",
            "epoch 8/25 batch 1000/1563\n",
            "epoch 8/25 batch 1200/1563\n",
            "epoch 8/25 batch 1400/1563\n",
            "epoch: 9 \n",
            " train loss: 0.0134, train accuracy: 0.85294 \n",
            " val loss: 0.014175760881602764 val accuracy: 0.8492\n",
            "\n",
            "\n",
            "epoch 9/25 batch 0/1563\n",
            "epoch 9/25 batch 200/1563\n",
            "epoch 9/25 batch 400/1563\n",
            "epoch 9/25 batch 600/1563\n",
            "epoch 9/25 batch 800/1563\n",
            "epoch 9/25 batch 1000/1563\n",
            "epoch 9/25 batch 1200/1563\n",
            "epoch 9/25 batch 1400/1563\n",
            "epoch: 10 \n",
            " train loss: 0.0125, train accuracy: 0.86272 \n",
            " val loss: 0.01323093895688653 val accuracy: 0.8549\n",
            "\n",
            "\n",
            "epoch 10/25 batch 0/1563\n",
            "epoch 10/25 batch 200/1563\n",
            "epoch 10/25 batch 400/1563\n",
            "epoch 10/25 batch 600/1563\n",
            "epoch 10/25 batch 800/1563\n",
            "epoch 10/25 batch 1000/1563\n",
            "epoch 10/25 batch 1200/1563\n",
            "epoch 10/25 batch 1400/1563\n",
            "epoch: 11 \n",
            " train loss: 0.0117, train accuracy: 0.87204 \n",
            " val loss: 0.017684717938303948 val accuracy: 0.8152\n",
            "\n",
            "\n",
            "epoch 11/25 batch 0/1563\n",
            "epoch 11/25 batch 200/1563\n",
            "epoch 11/25 batch 400/1563\n",
            "epoch 11/25 batch 600/1563\n",
            "epoch 11/25 batch 800/1563\n",
            "epoch 11/25 batch 1000/1563\n",
            "epoch 11/25 batch 1200/1563\n",
            "epoch 11/25 batch 1400/1563\n",
            "epoch: 12 \n",
            " train loss: 0.0110, train accuracy: 0.87994 \n",
            " val loss: 0.013193112643808126 val accuracy: 0.861\n",
            "\n",
            "\n",
            "epoch 12/25 batch 0/1563\n",
            "epoch 12/25 batch 200/1563\n",
            "epoch 12/25 batch 400/1563\n",
            "epoch 12/25 batch 600/1563\n",
            "epoch 12/25 batch 800/1563\n",
            "epoch 12/25 batch 1000/1563\n",
            "epoch 12/25 batch 1200/1563\n",
            "epoch 12/25 batch 1400/1563\n",
            "epoch: 13 \n",
            " train loss: 0.0104, train accuracy: 0.88476 \n",
            " val loss: 0.013573959298431873 val accuracy: 0.8577\n",
            "\n",
            "\n",
            "epoch 13/25 batch 0/1563\n",
            "epoch 13/25 batch 200/1563\n",
            "epoch 13/25 batch 400/1563\n",
            "epoch 13/25 batch 600/1563\n",
            "epoch 13/25 batch 800/1563\n",
            "epoch 13/25 batch 1000/1563\n",
            "epoch 13/25 batch 1200/1563\n",
            "epoch 13/25 batch 1400/1563\n",
            "epoch: 14 \n",
            " train loss: 0.0097, train accuracy: 0.89374 \n",
            " val loss: 0.014805515330284834 val accuracy: 0.8498\n",
            "\n",
            "\n",
            "epoch 14/25 batch 0/1563\n",
            "epoch 14/25 batch 200/1563\n",
            "epoch 14/25 batch 400/1563\n",
            "epoch 14/25 batch 600/1563\n",
            "epoch 14/25 batch 800/1563\n",
            "epoch 14/25 batch 1000/1563\n",
            "epoch 14/25 batch 1200/1563\n",
            "epoch 14/25 batch 1400/1563\n",
            "epoch: 15 \n",
            " train loss: 0.0094, train accuracy: 0.89676 \n",
            " val loss: 0.021592135063558816 val accuracy: 0.7816\n",
            "\n",
            "\n",
            "epoch 15/25 batch 0/1563\n",
            "epoch 15/25 batch 200/1563\n",
            "epoch 15/25 batch 400/1563\n",
            "epoch 15/25 batch 600/1563\n",
            "epoch 15/25 batch 800/1563\n",
            "epoch 15/25 batch 1000/1563\n",
            "epoch 15/25 batch 1200/1563\n",
            "epoch 15/25 batch 1400/1563\n",
            "epoch: 16 \n",
            " train loss: 0.0089, train accuracy: 0.90124 \n",
            " val loss: 0.01231290183365345 val accuracy: 0.8719\n",
            "\n",
            "\n",
            "epoch 16/25 batch 0/1563\n",
            "epoch 16/25 batch 200/1563\n",
            "epoch 16/25 batch 400/1563\n",
            "epoch 16/25 batch 600/1563\n",
            "epoch 16/25 batch 800/1563\n",
            "epoch 16/25 batch 1000/1563\n",
            "epoch 16/25 batch 1200/1563\n",
            "epoch 16/25 batch 1400/1563\n",
            "epoch: 17 \n",
            " train loss: 0.0084, train accuracy: 0.90662 \n",
            " val loss: 0.014234529457986355 val accuracy: 0.8574\n",
            "\n",
            "\n",
            "epoch 17/25 batch 0/1563\n",
            "epoch 17/25 batch 200/1563\n",
            "epoch 17/25 batch 400/1563\n",
            "epoch 17/25 batch 600/1563\n",
            "epoch 17/25 batch 800/1563\n",
            "epoch 17/25 batch 1000/1563\n",
            "epoch 17/25 batch 1200/1563\n",
            "epoch 17/25 batch 1400/1563\n",
            "epoch: 18 \n",
            " train loss: 0.0081, train accuracy: 0.91006 \n",
            " val loss: 0.012507618090510368 val accuracy: 0.869\n",
            "\n",
            "\n",
            "epoch 18/25 batch 0/1563\n",
            "epoch 18/25 batch 200/1563\n",
            "epoch 18/25 batch 400/1563\n",
            "epoch 18/25 batch 600/1563\n",
            "epoch 18/25 batch 800/1563\n",
            "epoch 18/25 batch 1000/1563\n",
            "epoch 18/25 batch 1200/1563\n",
            "epoch 18/25 batch 1400/1563\n",
            "epoch: 19 \n",
            " train loss: 0.0075, train accuracy: 0.91702 \n",
            " val loss: 0.011923542466014623 val accuracy: 0.88\n",
            "\n",
            "\n",
            "epoch 19/25 batch 0/1563\n",
            "epoch 19/25 batch 200/1563\n",
            "epoch 19/25 batch 400/1563\n",
            "epoch 19/25 batch 600/1563\n",
            "epoch 19/25 batch 800/1563\n",
            "epoch 19/25 batch 1000/1563\n",
            "epoch 19/25 batch 1200/1563\n",
            "epoch 19/25 batch 1400/1563\n",
            "epoch: 20 \n",
            " train loss: 0.0071, train accuracy: 0.92134 \n",
            " val loss: 0.013083346965909005 val accuracy: 0.8678\n",
            "\n",
            "\n",
            "epoch 20/25 batch 0/1563\n",
            "epoch 20/25 batch 200/1563\n",
            "epoch 20/25 batch 400/1563\n",
            "epoch 20/25 batch 600/1563\n",
            "epoch 20/25 batch 800/1563\n",
            "epoch 20/25 batch 1000/1563\n",
            "epoch 20/25 batch 1200/1563\n",
            "epoch 20/25 batch 1400/1563\n",
            "epoch: 21 \n",
            " train loss: 0.0069, train accuracy: 0.92168 \n",
            " val loss: 0.012439428311167285 val accuracy: 0.8761\n",
            "\n",
            "\n",
            "epoch 21/25 batch 0/1563\n",
            "epoch 21/25 batch 200/1563\n",
            "epoch 21/25 batch 400/1563\n",
            "epoch 21/25 batch 600/1563\n",
            "epoch 21/25 batch 800/1563\n",
            "epoch 21/25 batch 1000/1563\n",
            "epoch 21/25 batch 1200/1563\n",
            "epoch 21/25 batch 1400/1563\n",
            "epoch: 22 \n",
            " train loss: 0.0067, train accuracy: 0.9259 \n",
            " val loss: 0.012962869992107154 val accuracy: 0.8704\n",
            "\n",
            "\n",
            "epoch 22/25 batch 0/1563\n",
            "epoch 22/25 batch 200/1563\n",
            "epoch 22/25 batch 400/1563\n",
            "epoch 22/25 batch 600/1563\n",
            "epoch 22/25 batch 800/1563\n",
            "epoch 22/25 batch 1000/1563\n",
            "epoch 22/25 batch 1200/1563\n",
            "epoch 22/25 batch 1400/1563\n",
            "epoch: 23 \n",
            " train loss: 0.0062, train accuracy: 0.9313 \n",
            " val loss: 0.012345502335205673 val accuracy: 0.8768\n",
            "\n",
            "\n",
            "epoch 23/25 batch 0/1563\n",
            "epoch 23/25 batch 200/1563\n",
            "epoch 23/25 batch 400/1563\n",
            "epoch 23/25 batch 600/1563\n",
            "epoch 23/25 batch 800/1563\n",
            "epoch 23/25 batch 1000/1563\n",
            "epoch 23/25 batch 1200/1563\n",
            "epoch 23/25 batch 1400/1563\n",
            "epoch: 24 \n",
            " train loss: 0.0060, train accuracy: 0.93412 \n",
            " val loss: 0.011930602091923356 val accuracy: 0.8856\n",
            "\n",
            "\n",
            "epoch 24/25 batch 0/1563\n",
            "epoch 24/25 batch 200/1563\n",
            "epoch 24/25 batch 400/1563\n",
            "epoch 24/25 batch 600/1563\n",
            "epoch 24/25 batch 800/1563\n",
            "epoch 24/25 batch 1000/1563\n",
            "epoch 24/25 batch 1200/1563\n",
            "epoch 24/25 batch 1400/1563\n",
            "epoch: 25 \n",
            " train loss: 0.0058, train accuracy: 0.93592 \n",
            " val loss: 0.01235161579232663 val accuracy: 0.8826\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_teacher(25, teacher_model)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B5RPJMZbCgxr",
        "outputId": "f0f5acbd-3d9c-4f38-8fdb-ad1a0aa80310"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/25 batch 0/1563\n",
            "epoch 0/25 batch 200/1563\n",
            "epoch 0/25 batch 400/1563\n",
            "epoch 0/25 batch 600/1563\n",
            "epoch 0/25 batch 800/1563\n",
            "epoch 0/25 batch 1000/1563\n",
            "epoch 0/25 batch 1200/1563\n",
            "epoch 0/25 batch 1400/1563\n",
            "epoch: 1 \n",
            " train loss: 0.04463708773255348, train accuracy: 0.47682 \n",
            " val loss: 0.03884551301598549 val accuracy: 0.5555\n",
            "\n",
            "\n",
            "epoch 1/25 batch 0/1563\n",
            "epoch 1/25 batch 200/1563\n",
            "epoch 1/25 batch 400/1563\n",
            "epoch 1/25 batch 600/1563\n",
            "epoch 1/25 batch 800/1563\n",
            "epoch 1/25 batch 1000/1563\n",
            "epoch 1/25 batch 1200/1563\n",
            "epoch 1/25 batch 1400/1563\n",
            "epoch: 2 \n",
            " train loss: 0.03130469098687172, train accuracy: 0.64506 \n",
            " val loss: 0.027802370488643646 val accuracy: 0.6841\n",
            "\n",
            "\n",
            "epoch 2/25 batch 0/1563\n",
            "epoch 2/25 batch 200/1563\n",
            "epoch 2/25 batch 400/1563\n",
            "epoch 2/25 batch 600/1563\n",
            "epoch 2/25 batch 800/1563\n",
            "epoch 2/25 batch 1000/1563\n",
            "epoch 2/25 batch 1200/1563\n",
            "epoch 2/25 batch 1400/1563\n",
            "epoch: 3 \n",
            " train loss: 0.02598254755139351, train accuracy: 0.70854 \n",
            " val loss: 0.027887172996997833 val accuracy: 0.6851\n",
            "\n",
            "\n",
            "epoch 3/25 batch 0/1563\n",
            "epoch 3/25 batch 200/1563\n",
            "epoch 3/25 batch 400/1563\n",
            "epoch 3/25 batch 600/1563\n",
            "epoch 3/25 batch 800/1563\n",
            "epoch 3/25 batch 1000/1563\n",
            "epoch 3/25 batch 1200/1563\n",
            "epoch 3/25 batch 1400/1563\n",
            "epoch: 4 \n",
            " train loss: 0.02290264144539833, train accuracy: 0.74422 \n",
            " val loss: 0.023474974557757378 val accuracy: 0.7419\n",
            "\n",
            "\n",
            "epoch 4/25 batch 0/1563\n",
            "epoch 4/25 batch 200/1563\n",
            "epoch 4/25 batch 400/1563\n",
            "epoch 4/25 batch 600/1563\n",
            "epoch 4/25 batch 800/1563\n",
            "epoch 4/25 batch 1000/1563\n",
            "epoch 4/25 batch 1200/1563\n",
            "epoch 4/25 batch 1400/1563\n",
            "epoch: 5 \n",
            " train loss: 0.02075967937707901, train accuracy: 0.76894 \n",
            " val loss: 0.021474536508321762 val accuracy: 0.7699\n",
            "\n",
            "\n",
            "epoch 5/25 batch 0/1563\n",
            "epoch 5/25 batch 200/1563\n",
            "epoch 5/25 batch 400/1563\n",
            "epoch 5/25 batch 600/1563\n",
            "epoch 5/25 batch 800/1563\n",
            "epoch 5/25 batch 1000/1563\n",
            "epoch 5/25 batch 1200/1563\n",
            "epoch 5/25 batch 1400/1563\n",
            "epoch: 6 \n",
            " train loss: 0.018955638632178307, train accuracy: 0.78982 \n",
            " val loss: 0.021024545654654503 val accuracy: 0.7622\n",
            "\n",
            "\n",
            "epoch 6/25 batch 0/1563\n",
            "epoch 6/25 batch 200/1563\n",
            "epoch 6/25 batch 400/1563\n",
            "epoch 6/25 batch 600/1563\n",
            "epoch 6/25 batch 800/1563\n",
            "epoch 6/25 batch 1000/1563\n",
            "epoch 6/25 batch 1200/1563\n",
            "epoch 6/25 batch 1400/1563\n",
            "epoch: 7 \n",
            " train loss: 0.0179306548088789, train accuracy: 0.8001 \n",
            " val loss: 0.017461668699979782 val accuracy: 0.8117\n",
            "\n",
            "\n",
            "epoch 7/25 batch 0/1563\n",
            "epoch 7/25 batch 200/1563\n",
            "epoch 7/25 batch 400/1563\n",
            "epoch 7/25 batch 600/1563\n",
            "epoch 7/25 batch 800/1563\n",
            "epoch 7/25 batch 1000/1563\n",
            "epoch 7/25 batch 1200/1563\n",
            "epoch 7/25 batch 1400/1563\n",
            "epoch: 8 \n",
            " train loss: 0.01673535816371441, train accuracy: 0.81424 \n",
            " val loss: 0.017887720838189125 val accuracy: 0.8047\n",
            "\n",
            "\n",
            "epoch 8/25 batch 0/1563\n",
            "epoch 8/25 batch 200/1563\n",
            "epoch 8/25 batch 400/1563\n",
            "epoch 8/25 batch 600/1563\n",
            "epoch 8/25 batch 800/1563\n",
            "epoch 8/25 batch 1000/1563\n",
            "epoch 8/25 batch 1200/1563\n",
            "epoch 8/25 batch 1400/1563\n",
            "epoch: 9 \n",
            " train loss: 0.015687452629208565, train accuracy: 0.8261 \n",
            " val loss: 0.016136467456817627 val accuracy: 0.8217\n",
            "\n",
            "\n",
            "epoch 9/25 batch 0/1563\n",
            "epoch 9/25 batch 200/1563\n",
            "epoch 9/25 batch 400/1563\n",
            "epoch 9/25 batch 600/1563\n",
            "epoch 9/25 batch 800/1563\n",
            "epoch 9/25 batch 1000/1563\n",
            "epoch 9/25 batch 1200/1563\n",
            "epoch 9/25 batch 1400/1563\n",
            "epoch: 10 \n",
            " train loss: 0.014970552176237106, train accuracy: 0.83216 \n",
            " val loss: 0.017348475754261017 val accuracy: 0.8112\n",
            "\n",
            "\n",
            "epoch 10/25 batch 0/1563\n",
            "epoch 10/25 batch 200/1563\n",
            "epoch 10/25 batch 400/1563\n",
            "epoch 10/25 batch 600/1563\n",
            "epoch 10/25 batch 800/1563\n",
            "epoch 10/25 batch 1000/1563\n",
            "epoch 10/25 batch 1200/1563\n",
            "epoch 10/25 batch 1400/1563\n",
            "epoch: 11 \n",
            " train loss: 0.014218950644135475, train accuracy: 0.8418 \n",
            " val loss: 0.015441828407347202 val accuracy: 0.8343\n",
            "\n",
            "\n",
            "epoch 11/25 batch 0/1563\n",
            "epoch 11/25 batch 200/1563\n",
            "epoch 11/25 batch 400/1563\n",
            "epoch 11/25 batch 600/1563\n",
            "epoch 11/25 batch 800/1563\n",
            "epoch 11/25 batch 1000/1563\n",
            "epoch 11/25 batch 1200/1563\n",
            "epoch 11/25 batch 1400/1563\n",
            "epoch: 12 \n",
            " train loss: 0.01339296717196703, train accuracy: 0.85174 \n",
            " val loss: 0.017185542732477188 val accuracy: 0.8223\n",
            "\n",
            "\n",
            "epoch 12/25 batch 0/1563\n",
            "epoch 12/25 batch 200/1563\n",
            "epoch 12/25 batch 400/1563\n",
            "epoch 12/25 batch 600/1563\n",
            "epoch 12/25 batch 800/1563\n",
            "epoch 12/25 batch 1000/1563\n",
            "epoch 12/25 batch 1200/1563\n",
            "epoch 12/25 batch 1400/1563\n",
            "epoch: 13 \n",
            " train loss: 0.013025345280766487, train accuracy: 0.85586 \n",
            " val loss: 0.014703892171382904 val accuracy: 0.8402\n",
            "\n",
            "\n",
            "epoch 13/25 batch 0/1563\n",
            "epoch 13/25 batch 200/1563\n",
            "epoch 13/25 batch 400/1563\n",
            "epoch 13/25 batch 600/1563\n",
            "epoch 13/25 batch 800/1563\n",
            "epoch 13/25 batch 1000/1563\n",
            "epoch 13/25 batch 1200/1563\n",
            "epoch 13/25 batch 1400/1563\n",
            "epoch: 14 \n",
            " train loss: 0.012459540739655495, train accuracy: 0.86216 \n",
            " val loss: 0.015566833317279816 val accuracy: 0.8333\n",
            "\n",
            "\n",
            "epoch 14/25 batch 0/1563\n",
            "epoch 14/25 batch 200/1563\n",
            "epoch 14/25 batch 400/1563\n",
            "epoch 14/25 batch 600/1563\n",
            "epoch 14/25 batch 800/1563\n",
            "epoch 14/25 batch 1000/1563\n",
            "epoch 14/25 batch 1200/1563\n",
            "epoch 14/25 batch 1400/1563\n",
            "epoch: 15 \n",
            " train loss: 0.011749666184186935, train accuracy: 0.86956 \n",
            " val loss: 0.01601334474980831 val accuracy: 0.8319\n",
            "\n",
            "\n",
            "epoch 15/25 batch 0/1563\n",
            "epoch 15/25 batch 200/1563\n",
            "epoch 15/25 batch 400/1563\n",
            "epoch 15/25 batch 600/1563\n",
            "epoch 15/25 batch 800/1563\n",
            "epoch 15/25 batch 1000/1563\n",
            "epoch 15/25 batch 1200/1563\n",
            "epoch 15/25 batch 1400/1563\n",
            "epoch: 16 \n",
            " train loss: 0.011580479331314564, train accuracy: 0.8701 \n",
            " val loss: 0.015448258258402348 val accuracy: 0.8296\n",
            "\n",
            "\n",
            "epoch 16/25 batch 0/1563\n",
            "epoch 16/25 batch 200/1563\n",
            "epoch 16/25 batch 400/1563\n",
            "epoch 16/25 batch 600/1563\n",
            "epoch 16/25 batch 800/1563\n",
            "epoch 16/25 batch 1000/1563\n",
            "epoch 16/25 batch 1200/1563\n",
            "epoch 16/25 batch 1400/1563\n",
            "epoch: 17 \n",
            " train loss: 0.010963679291307926, train accuracy: 0.87782 \n",
            " val loss: 0.016305284574627876 val accuracy: 0.8325\n",
            "\n",
            "\n",
            "epoch 17/25 batch 0/1563\n",
            "epoch 17/25 batch 200/1563\n",
            "epoch 17/25 batch 400/1563\n",
            "epoch 17/25 batch 600/1563\n",
            "epoch 17/25 batch 800/1563\n",
            "epoch 17/25 batch 1000/1563\n",
            "epoch 17/25 batch 1200/1563\n",
            "epoch 17/25 batch 1400/1563\n",
            "epoch: 18 \n",
            " train loss: 0.010508950799703598, train accuracy: 0.88074 \n",
            " val loss: 0.01420841459184885 val accuracy: 0.8462\n",
            "\n",
            "\n",
            "epoch 18/25 batch 0/1563\n",
            "epoch 18/25 batch 200/1563\n",
            "epoch 18/25 batch 400/1563\n",
            "epoch 18/25 batch 600/1563\n",
            "epoch 18/25 batch 800/1563\n",
            "epoch 18/25 batch 1000/1563\n",
            "epoch 18/25 batch 1200/1563\n",
            "epoch 18/25 batch 1400/1563\n",
            "epoch: 19 \n",
            " train loss: 0.010080143809318542, train accuracy: 0.88638 \n",
            " val loss: 0.0162754375487566 val accuracy: 0.8247\n",
            "\n",
            "\n",
            "epoch 19/25 batch 0/1563\n",
            "epoch 19/25 batch 200/1563\n",
            "epoch 19/25 batch 400/1563\n",
            "epoch 19/25 batch 600/1563\n",
            "epoch 19/25 batch 800/1563\n",
            "epoch 19/25 batch 1000/1563\n",
            "epoch 19/25 batch 1200/1563\n",
            "epoch 19/25 batch 1400/1563\n",
            "epoch: 20 \n",
            " train loss: 0.009774900041520596, train accuracy: 0.89026 \n",
            " val loss: 0.013971662148833275 val accuracy: 0.8512\n",
            "\n",
            "\n",
            "epoch 20/25 batch 0/1563\n",
            "epoch 20/25 batch 200/1563\n",
            "epoch 20/25 batch 400/1563\n",
            "epoch 20/25 batch 600/1563\n",
            "epoch 20/25 batch 800/1563\n",
            "epoch 20/25 batch 1000/1563\n",
            "epoch 20/25 batch 1200/1563\n",
            "epoch 20/25 batch 1400/1563\n",
            "epoch: 21 \n",
            " train loss: 0.009667815640568733, train accuracy: 0.89158 \n",
            " val loss: 0.013648731634020805 val accuracy: 0.8551\n",
            "\n",
            "\n",
            "epoch 21/25 batch 0/1563\n",
            "epoch 21/25 batch 200/1563\n",
            "epoch 21/25 batch 400/1563\n",
            "epoch 21/25 batch 600/1563\n",
            "epoch 21/25 batch 800/1563\n",
            "epoch 21/25 batch 1000/1563\n",
            "epoch 21/25 batch 1200/1563\n",
            "epoch 21/25 batch 1400/1563\n",
            "epoch: 22 \n",
            " train loss: 0.009164419025182724, train accuracy: 0.89766 \n",
            " val loss: 0.015864286571741104 val accuracy: 0.8354\n",
            "\n",
            "\n",
            "epoch 22/25 batch 0/1563\n",
            "epoch 22/25 batch 200/1563\n",
            "epoch 22/25 batch 400/1563\n",
            "epoch 22/25 batch 600/1563\n",
            "epoch 22/25 batch 800/1563\n",
            "epoch 22/25 batch 1000/1563\n",
            "epoch 22/25 batch 1200/1563\n",
            "epoch 22/25 batch 1400/1563\n",
            "epoch: 23 \n",
            " train loss: 0.008937720209360123, train accuracy: 0.8992 \n",
            " val loss: 0.015098937787115574 val accuracy: 0.8427\n",
            "\n",
            "\n",
            "epoch 23/25 batch 0/1563\n",
            "epoch 23/25 batch 200/1563\n",
            "epoch 23/25 batch 400/1563\n",
            "epoch 23/25 batch 600/1563\n",
            "epoch 23/25 batch 800/1563\n",
            "epoch 23/25 batch 1000/1563\n",
            "epoch 23/25 batch 1200/1563\n",
            "epoch 23/25 batch 1400/1563\n",
            "epoch: 24 \n",
            " train loss: 0.008579622022807598, train accuracy: 0.90446 \n",
            " val loss: 0.01534048281610012 val accuracy: 0.8445\n",
            "\n",
            "\n",
            "epoch 24/25 batch 0/1563\n",
            "epoch 24/25 batch 200/1563\n",
            "epoch 24/25 batch 400/1563\n",
            "epoch 24/25 batch 600/1563\n",
            "epoch 24/25 batch 800/1563\n",
            "epoch 24/25 batch 1000/1563\n",
            "epoch 24/25 batch 1200/1563\n",
            "epoch 24/25 batch 1400/1563\n",
            "epoch: 25 \n",
            " train loss: 0.008312055841088295, train accuracy: 0.90566 \n",
            " val loss: 0.01314817275851965 val accuracy: 0.8624\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_student(25, initial_student_model)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4F10IaEcCgxr",
        "outputId": "e869e2d2-2d08-47ec-836e-df2cd2cfac22"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/25 batch 0/1563\n",
            "epoch 0/25 batch 200/1563\n",
            "epoch 0/25 batch 400/1563\n",
            "epoch 0/25 batch 600/1563\n",
            "epoch 0/25 batch 800/1563\n",
            "epoch 0/25 batch 1000/1563\n",
            "epoch 0/25 batch 1200/1563\n",
            "epoch 0/25 batch 1400/1563\n",
            "epoch: 1 \n",
            " train loss: -14.998409271240234, train accuracy: 0.52716 \n",
            " val loss: -15.020909309387207 val accuracy: 0.6127\n",
            "\n",
            "\n",
            "epoch 1/25 batch 0/1563\n",
            "epoch 1/25 batch 200/1563\n",
            "epoch 1/25 batch 400/1563\n",
            "epoch 1/25 batch 600/1563\n",
            "epoch 1/25 batch 800/1563\n",
            "epoch 1/25 batch 1000/1563\n",
            "epoch 1/25 batch 1200/1563\n",
            "epoch 1/25 batch 1400/1563\n",
            "epoch: 2 \n",
            " train loss: -15.00456428527832, train accuracy: 0.69394 \n",
            " val loss: -15.025636672973633 val accuracy: 0.7285\n",
            "\n",
            "\n",
            "epoch 2/25 batch 0/1563\n",
            "epoch 2/25 batch 200/1563\n",
            "epoch 2/25 batch 400/1563\n",
            "epoch 2/25 batch 600/1563\n",
            "epoch 2/25 batch 800/1563\n",
            "epoch 2/25 batch 1000/1563\n",
            "epoch 2/25 batch 1200/1563\n",
            "epoch 2/25 batch 1400/1563\n",
            "epoch: 3 \n",
            " train loss: -15.006563186645508, train accuracy: 0.74438 \n",
            " val loss: -15.025818824768066 val accuracy: 0.7383\n",
            "\n",
            "\n",
            "epoch 3/25 batch 0/1563\n",
            "epoch 3/25 batch 200/1563\n",
            "epoch 3/25 batch 400/1563\n",
            "epoch 3/25 batch 600/1563\n",
            "epoch 3/25 batch 800/1563\n",
            "epoch 3/25 batch 1000/1563\n",
            "epoch 3/25 batch 1200/1563\n",
            "epoch 3/25 batch 1400/1563\n",
            "epoch: 4 \n",
            " train loss: -15.007790565490723, train accuracy: 0.77658 \n",
            " val loss: -15.027235984802246 val accuracy: 0.7709\n",
            "\n",
            "\n",
            "epoch 4/25 batch 0/1563\n",
            "epoch 4/25 batch 200/1563\n",
            "epoch 4/25 batch 400/1563\n",
            "epoch 4/25 batch 600/1563\n",
            "epoch 4/25 batch 800/1563\n",
            "epoch 4/25 batch 1000/1563\n",
            "epoch 4/25 batch 1200/1563\n",
            "epoch 4/25 batch 1400/1563\n",
            "epoch: 5 \n",
            " train loss: -15.008657455444336, train accuracy: 0.79968 \n",
            " val loss: -15.025571823120117 val accuracy: 0.7297\n",
            "\n",
            "\n",
            "epoch 5/25 batch 0/1563\n",
            "epoch 5/25 batch 200/1563\n",
            "epoch 5/25 batch 400/1563\n",
            "epoch 5/25 batch 600/1563\n",
            "epoch 5/25 batch 800/1563\n",
            "epoch 5/25 batch 1000/1563\n",
            "epoch 5/25 batch 1200/1563\n",
            "epoch 5/25 batch 1400/1563\n",
            "epoch: 6 \n",
            " train loss: -15.009264945983887, train accuracy: 0.81502 \n",
            " val loss: -15.029268264770508 val accuracy: 0.8233\n",
            "\n",
            "\n",
            "epoch 6/25 batch 0/1563\n",
            "epoch 6/25 batch 200/1563\n",
            "epoch 6/25 batch 400/1563\n",
            "epoch 6/25 batch 600/1563\n",
            "epoch 6/25 batch 800/1563\n",
            "epoch 6/25 batch 1000/1563\n",
            "epoch 6/25 batch 1200/1563\n",
            "epoch 6/25 batch 1400/1563\n",
            "epoch: 7 \n",
            " train loss: -15.009800910949707, train accuracy: 0.829 \n",
            " val loss: -15.029316902160645 val accuracy: 0.8159\n",
            "\n",
            "\n",
            "epoch 7/25 batch 0/1563\n",
            "epoch 7/25 batch 200/1563\n",
            "epoch 7/25 batch 400/1563\n",
            "epoch 7/25 batch 600/1563\n",
            "epoch 7/25 batch 800/1563\n",
            "epoch 7/25 batch 1000/1563\n",
            "epoch 7/25 batch 1200/1563\n",
            "epoch 7/25 batch 1400/1563\n",
            "epoch: 8 \n",
            " train loss: -15.010129928588867, train accuracy: 0.83674 \n",
            " val loss: -15.02893352508545 val accuracy: 0.8062\n",
            "\n",
            "\n",
            "epoch 8/25 batch 0/1563\n",
            "epoch 8/25 batch 200/1563\n",
            "epoch 8/25 batch 400/1563\n",
            "epoch 8/25 batch 600/1563\n",
            "epoch 8/25 batch 800/1563\n",
            "epoch 8/25 batch 1000/1563\n",
            "epoch 8/25 batch 1200/1563\n",
            "epoch 8/25 batch 1400/1563\n",
            "epoch: 9 \n",
            " train loss: -15.010528564453125, train accuracy: 0.8468 \n",
            " val loss: -15.030029296875 val accuracy: 0.8407\n",
            "\n",
            "\n",
            "epoch 9/25 batch 0/1563\n",
            "epoch 9/25 batch 200/1563\n",
            "epoch 9/25 batch 400/1563\n",
            "epoch 9/25 batch 600/1563\n",
            "epoch 9/25 batch 800/1563\n",
            "epoch 9/25 batch 1000/1563\n",
            "epoch 9/25 batch 1200/1563\n",
            "epoch 9/25 batch 1400/1563\n",
            "epoch: 10 \n",
            " train loss: -15.010824203491211, train accuracy: 0.85478 \n",
            " val loss: -15.029704093933105 val accuracy: 0.8273\n",
            "\n",
            "\n",
            "epoch 10/25 batch 0/1563\n",
            "epoch 10/25 batch 200/1563\n",
            "epoch 10/25 batch 400/1563\n",
            "epoch 10/25 batch 600/1563\n",
            "epoch 10/25 batch 800/1563\n",
            "epoch 10/25 batch 1000/1563\n",
            "epoch 10/25 batch 1200/1563\n",
            "epoch 10/25 batch 1400/1563\n",
            "epoch: 11 \n",
            " train loss: -15.01109504699707, train accuracy: 0.86244 \n",
            " val loss: -15.029921531677246 val accuracy: 0.8326\n",
            "\n",
            "\n",
            "epoch 11/25 batch 0/1563\n",
            "epoch 11/25 batch 200/1563\n",
            "epoch 11/25 batch 400/1563\n",
            "epoch 11/25 batch 600/1563\n",
            "epoch 11/25 batch 800/1563\n",
            "epoch 11/25 batch 1000/1563\n",
            "epoch 11/25 batch 1200/1563\n",
            "epoch 11/25 batch 1400/1563\n",
            "epoch: 12 \n",
            " train loss: -15.011321067810059, train accuracy: 0.8688 \n",
            " val loss: -15.029638290405273 val accuracy: 0.8306\n",
            "\n",
            "\n",
            "epoch 12/25 batch 0/1563\n",
            "epoch 12/25 batch 200/1563\n",
            "epoch 12/25 batch 400/1563\n",
            "epoch 12/25 batch 600/1563\n",
            "epoch 12/25 batch 800/1563\n",
            "epoch 12/25 batch 1000/1563\n",
            "epoch 12/25 batch 1200/1563\n",
            "epoch 12/25 batch 1400/1563\n",
            "epoch: 13 \n",
            " train loss: -15.011483192443848, train accuracy: 0.87292 \n",
            " val loss: -15.03034782409668 val accuracy: 0.8472\n",
            "\n",
            "\n",
            "epoch 13/25 batch 0/1563\n",
            "epoch 13/25 batch 200/1563\n",
            "epoch 13/25 batch 400/1563\n",
            "epoch 13/25 batch 600/1563\n",
            "epoch 13/25 batch 800/1563\n",
            "epoch 13/25 batch 1000/1563\n",
            "epoch 13/25 batch 1200/1563\n",
            "epoch 13/25 batch 1400/1563\n",
            "epoch: 14 \n",
            " train loss: -15.011747360229492, train accuracy: 0.88002 \n",
            " val loss: -15.030729293823242 val accuracy: 0.8532\n",
            "\n",
            "\n",
            "epoch 14/25 batch 0/1563\n",
            "epoch 14/25 batch 200/1563\n",
            "epoch 14/25 batch 400/1563\n",
            "epoch 14/25 batch 600/1563\n",
            "epoch 14/25 batch 800/1563\n",
            "epoch 14/25 batch 1000/1563\n",
            "epoch 14/25 batch 1200/1563\n",
            "epoch 14/25 batch 1400/1563\n",
            "epoch: 15 \n",
            " train loss: -15.011920928955078, train accuracy: 0.8851 \n",
            " val loss: -15.030105590820312 val accuracy: 0.8395\n",
            "\n",
            "\n",
            "epoch 15/25 batch 0/1563\n",
            "epoch 15/25 batch 200/1563\n",
            "epoch 15/25 batch 400/1563\n",
            "epoch 15/25 batch 600/1563\n",
            "epoch 15/25 batch 800/1563\n",
            "epoch 15/25 batch 1000/1563\n",
            "epoch 15/25 batch 1200/1563\n",
            "epoch 15/25 batch 1400/1563\n",
            "epoch: 16 \n",
            " train loss: -15.0120849609375, train accuracy: 0.8891 \n",
            " val loss: -15.0309419631958 val accuracy: 0.8624\n",
            "\n",
            "\n",
            "epoch 16/25 batch 0/1563\n",
            "epoch 16/25 batch 200/1563\n",
            "epoch 16/25 batch 400/1563\n",
            "epoch 16/25 batch 600/1563\n",
            "epoch 16/25 batch 800/1563\n",
            "epoch 16/25 batch 1000/1563\n",
            "epoch 16/25 batch 1200/1563\n",
            "epoch 16/25 batch 1400/1563\n",
            "epoch: 17 \n",
            " train loss: -15.012251853942871, train accuracy: 0.8949 \n",
            " val loss: -15.030753135681152 val accuracy: 0.852\n",
            "\n",
            "\n",
            "epoch 17/25 batch 0/1563\n",
            "epoch 17/25 batch 200/1563\n",
            "epoch 17/25 batch 400/1563\n",
            "epoch 17/25 batch 600/1563\n",
            "epoch 17/25 batch 800/1563\n",
            "epoch 17/25 batch 1000/1563\n",
            "epoch 17/25 batch 1200/1563\n",
            "epoch 17/25 batch 1400/1563\n",
            "epoch: 18 \n",
            " train loss: -15.012422561645508, train accuracy: 0.89764 \n",
            " val loss: -15.030193328857422 val accuracy: 0.8387\n",
            "\n",
            "\n",
            "epoch 18/25 batch 0/1563\n",
            "epoch 18/25 batch 200/1563\n",
            "epoch 18/25 batch 400/1563\n",
            "epoch 18/25 batch 600/1563\n",
            "epoch 18/25 batch 800/1563\n",
            "epoch 18/25 batch 1000/1563\n",
            "epoch 18/25 batch 1200/1563\n",
            "epoch 18/25 batch 1400/1563\n",
            "epoch: 19 \n",
            " train loss: -15.012554168701172, train accuracy: 0.90134 \n",
            " val loss: -15.03122329711914 val accuracy: 0.8669\n",
            "\n",
            "\n",
            "epoch 19/25 batch 0/1563\n",
            "epoch 19/25 batch 200/1563\n",
            "epoch 19/25 batch 400/1563\n",
            "epoch 19/25 batch 600/1563\n",
            "epoch 19/25 batch 800/1563\n",
            "epoch 19/25 batch 1000/1563\n",
            "epoch 19/25 batch 1200/1563\n",
            "epoch 19/25 batch 1400/1563\n",
            "epoch: 20 \n",
            " train loss: -15.012649536132812, train accuracy: 0.90534 \n",
            " val loss: -15.03122329711914 val accuracy: 0.8633\n",
            "\n",
            "\n",
            "epoch 20/25 batch 0/1563\n",
            "epoch 20/25 batch 200/1563\n",
            "epoch 20/25 batch 400/1563\n",
            "epoch 20/25 batch 600/1563\n",
            "epoch 20/25 batch 800/1563\n",
            "epoch 20/25 batch 1000/1563\n",
            "epoch 20/25 batch 1200/1563\n",
            "epoch 20/25 batch 1400/1563\n",
            "epoch: 21 \n",
            " train loss: -15.012782096862793, train accuracy: 0.90932 \n",
            " val loss: -15.031132698059082 val accuracy: 0.863\n",
            "\n",
            "\n",
            "epoch 21/25 batch 0/1563\n",
            "epoch 21/25 batch 200/1563\n",
            "epoch 21/25 batch 400/1563\n",
            "epoch 21/25 batch 600/1563\n",
            "epoch 21/25 batch 800/1563\n",
            "epoch 21/25 batch 1000/1563\n",
            "epoch 21/25 batch 1200/1563\n",
            "epoch 21/25 batch 1400/1563\n",
            "epoch: 22 \n",
            " train loss: -15.012901306152344, train accuracy: 0.91196 \n",
            " val loss: -15.03121566772461 val accuracy: 0.8661\n",
            "\n",
            "\n",
            "epoch 22/25 batch 0/1563\n",
            "epoch 22/25 batch 200/1563\n",
            "epoch 22/25 batch 400/1563\n",
            "epoch 22/25 batch 600/1563\n",
            "epoch 22/25 batch 800/1563\n",
            "epoch 22/25 batch 1000/1563\n",
            "epoch 22/25 batch 1200/1563\n",
            "epoch 22/25 batch 1400/1563\n",
            "epoch: 23 \n",
            " train loss: -15.012939453125, train accuracy: 0.91314 \n",
            " val loss: -15.03156852722168 val accuracy: 0.8766\n",
            "\n",
            "\n",
            "epoch 23/25 batch 0/1563\n",
            "epoch 23/25 batch 200/1563\n",
            "epoch 23/25 batch 400/1563\n",
            "epoch 23/25 batch 600/1563\n",
            "epoch 23/25 batch 800/1563\n",
            "epoch 23/25 batch 1000/1563\n",
            "epoch 23/25 batch 1200/1563\n",
            "epoch 23/25 batch 1400/1563\n",
            "epoch: 24 \n",
            " train loss: -15.013083457946777, train accuracy: 0.91756 \n",
            " val loss: -15.031340599060059 val accuracy: 0.8687\n",
            "\n",
            "\n",
            "epoch 24/25 batch 0/1563\n",
            "epoch 24/25 batch 200/1563\n",
            "epoch 24/25 batch 400/1563\n",
            "epoch 24/25 batch 600/1563\n",
            "epoch 24/25 batch 800/1563\n",
            "epoch 24/25 batch 1000/1563\n",
            "epoch 24/25 batch 1200/1563\n",
            "epoch 24/25 batch 1400/1563\n",
            "epoch: 25 \n",
            " train loss: -15.013179779052734, train accuracy: 0.92042 \n",
            " val loss: -15.031204223632812 val accuracy: 0.8622\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "knowledge_distillation(25, distilled_student_model, teacher_model)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZJZ2nlY6Cgxs",
        "outputId": "6987f47f-1938-4c5f-db3b-8d893cfa97ef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher parameters amount: 19357706\n",
            "student parameters amount: 1771786\n"
          ]
        }
      ],
      "source": [
        "print(f\"teacher parameters amount: {sum(p.numel() for p in teacher_model.parameters())}\")\n",
        "print(f\"student parameters amount: {sum(p.numel() for p in initial_student_model.parameters())}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkRJopkICgxs",
        "outputId": "5e0e6501-5056-4c86-c64f-3762a51f8bf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " teacher accuracy: 0.8856 \n",
            " student accuracy: 0.8624 \n",
            " distilled student accuracy: 0.8766\n"
          ]
        }
      ],
      "source": [
        "print_models_evaluation_accuracy(initial_student_model, teacher_model, distilled_student_model)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIWkEokJCgxs",
        "outputId": "1086d33f-ae87-49cc-d056-e818ea00b8d4"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "knowledge-distillation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}